{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient 소실, 폭주"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 출력층으로 오차 gradient를 전파하면서 진행되고, 알고리즘이 신경망의 모든 파라미터에 대한 오차 함수의 gradient(기울기)를 계산하면 경사 하강법 단계에서 gradient를 사용해 각 파라미터를 수정함.\n",
    "* 그러나, 알고리즘이 하위 층으로 진행될수록 gradient가 점점 작아지게 되고, 이러한 가중치를 변경되지 않은 채로 둔다면 좋은 솔루션으로 수렴되지 않게 됨. 이를 그레이디언트 소실(vanishing gradient)라고 함.\n",
    "* 또한, 그레이디언트가 점점 커져 여러 층이 비정상적으로 큰 가중치로 갱신되면 알고리즘이 발산(diverse)하는데 이를 그레이디언트 폭주(exploding gradient)라고 함.\n",
    "  * 불안정한 gradient는 층마다 학습 속도를 달라지게 만들기 때문에 심층 신경망 훈련을 어렵게 함.\n",
    "  * sigmoid 활성화 함수와, 정규분포를 기반으로 한 가중치 초기화 방법으로 인해 각 층에서 출력의 분산이 입력의 분산보다 크다는 게 밝혀져, 신경망의 위쪽으로 갈수록 분산이 계속 커져 결국에는 가장 높은 층에서 활성화 함수가 0이나 1로 수렴해버림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gradient 문제를 해결하기 위해서는 각 층의 출력에 대한 분산이 입력에 대한 분산과 같아야 하고, 역방향에서 층을 통과하기 전과 후의 gradient 분산이 동일해야 한다는 주장이 많음.\n",
    "  * 층의 입력과 출력 개수는 각각 층의 fan-in, fan-out이라고 함.\n",
    "* 이를 위해, 각 층의 연결 가중치를 아래의 방식대로 무작위로 초기화하는 데, 이를 Xavier 초기화(또는 Glorot 초기화)라고 함.\n",
    "$$ \\text{평균이 0이고 분산이}\\;\\sigma^2=\\frac{1}{fan_{\\text{avg}}}\\;인\\;정규분포$$\n",
    "$$또는\\;r=\\sqrt{\\frac{3}{fan_{\\text{avg}}}}일\\;때, -r과\\;+r사이의\\;균등분포$$\n",
    "$$(fan_{\\text{avg}}=(\\text{fan-in}+\\text{fan-out})/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * $fan_{\\text{avg}}$를 $fan_{\\text{in}}$으로 바꾸면 LuCun 초기화.\n",
    "* 위의 초기화 방식을 사용하면 훈련 속도가 상당히 높아짐.\n",
    "* 각 활성화 함수에 대한 초기화 전략은 위의 식에서 분산의 스케일링이나 fan_avg, fan_in중 어떤 것을 쓰느냐만 다름. 특별히 ReLU활성화 함수에 대한 초기화 방법은 He 초기화라고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|초기화 전략|활성화 함수|$\\sigma^2$(정규분포)|\n",
    "|----------|----------|--------------------|\n",
    "|Glorot    |tanh, softmax, sigmoid, 활성화 함수 없음|1/$fan_{\\text{avg}}$|\n",
    "|He        |ReLU      |2/$fan_{\\text{in}}$|\n",
    "|LuCun     |SELU      |1/$fan_{\\text{in}}$|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keras에서는 기본적으로 균등분포의 Glorot 초기화를 사용.\n",
    "* 다른 초기화를 사용하려면 층을 만들 때 <code>kernel_initalizer</code> 하이퍼파라미터를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1c924cc04f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# He 초기화 사용\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
    "\n",
    "# fan_in 대신 fan_avg기반의 균등분포 He 초기화(VarianceScaling 사용)\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\", distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * <code>VarianceScaling</code>의 매개변수 기본값 : scale=1.0, mode='fan_in', distribution='truncated_normal'.\n",
    ">   * distribution='truncated_normal' : 절단 정규분포. $\\sigma^2=1.3*scale/mode$ \n",
    ">   * distribution='untruncated_normal' : 정규분포. $\\sigma^2=scale/mode$\n",
    "> * kernel_initializer의 기본값은 'glorot_uniform'으로, <code>VarianceScaling(scale=1.0, mode='fan_avg', distribution='uniform')</code>과 동일.\n",
    ">   * 'he_normal'은 <code>VarianceScaling(scale=2., mode='fan_in', distribution='truncated_normal')</code>\n",
    ">   * 'lecun_normal'은 VarianceScaling의 기본값 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수를 잘못 선택하면 gradient 소실이나 폭주로 이어질 수 있음.\n",
    "* ReLU는 특정 양수값에 수렴하지 않는다는 장점이 있지만 ReLU는 완벽하지 않음.\n",
    "  * 훈련하는 동안 일부 뉴런이 0이외의 값을 출력하지 않게 되는 죽은 ReLU(dying ReLU)문제가 있음.\n",
    "  * 학습률이 크면 뉴런 절반이 죽어 있기도 함.\n",
    "  * 뉴런의 가중치가 바뀌어 훈련 세트의 모든 샘플에 대한 입력 가중치 합이 음수가 되면 뉴런이 죽게 됨. 가중치 합이 음수이면 ReLU의 gradient가 0이 되어 경사 하강법이 작동하지 않게 됨.\n",
    "* 이를 해결하기 위해 ReakyReLU라는 ReLU함수의 변종을 사용\n",
    "  * $\\text{LeakyReLU}_{\\alpha}(z)=\\text{max}(\\alpha z, z)$\n",
    "  * $\\alpha$ : 함수가 새는(leaku) 정도. 즉, z<0일때의 함수의 기울기. 일반적으로 0.01로 설정함.\n",
    "  * $\\alpha$ 덕분에 뉴런이 죽지 않게 만들어줌.\n",
    "  * ReLU보다 LeakyReLU가 항상 성능이 높음.\n",
    "  * RReLU(randomized leaky ReLU) : 훈련 시에는 $\\alpha$를 주어진 범위에서 무작위로 선택하고, 테스트 시에는 평균을 사용. 훈련 세트의 과대적합을 줄이는 규제의 역할을 하는 것 처럼 작동.\n",
    "  * PReLU(parametric leaky ReLU) : $\\alpha$가 훈련하는 동안에 학습됨. 대규모 이미지 데이터셋에서는 성능이 좋지만, 소규모 데이터셋에서는 과대적합될 가능성이 높음.\n",
    "* ELU(exponential linear unit) : 훈련 시간이 줄고 신경망의 테스트 세트 성능도 더 높은 함수.\n",
    "$ \\text{ELU}_{\\alpha}(z)=\\begin{cases}\n",
    "\\alpha(\\exp(z)-1), & if\\;z<0 \\\\\n",
    "z, & if\\;z\\geq0\n",
    "\\end{cases}$\n",
    "  * ReLU와 거의 비슷\n",
    "  * z<0때 음수값이 들어오므로 활성화 함수의 평균 출력이 0에 가까워짐. 그레이디언트 소실 문제를 완화해줌.\n",
    "  * $\\alpha$는 z가 큰 음수값일 떄 ELU가 수렴할 값을 정의. 주로 1로 설정하지만 변경 가능.\n",
    "  * z<0 일 때도 gradient가 0이 아니므로 죽은 뉴런을 만들지 않음.\n",
    "  * $\\alpha$=1이면 z=0에서 급격히 변동하지 않으므로 모든 구간에서 매끄럽기 때문에 경사 하강법의 속도를 높여줌.\n",
    "  * 단, ReLU와 다른 변종들보다 계산 속도가 느림.\n",
    "* SELU(Scaled ELU) : 스케일이 조정된 ELU함수의 변종.\n",
    "$ \\text{selu}(z)=\\lambda\\cdot\\text{ELU}_{\\alpha}(z)$\n",
    "  * 완전 연결 층만 쌓고, 모든 은닉층을 SELU활성화 함수를 사용하도록 하면 네트워크가 자기 정규화됨. (훈련하는 동안 각 층의 출력이 평균은 0, 표준편차는 1을 유지하는 경향이 있음). 이는 gradient 소실과 폭주 문제를 막아줌.\n",
    "  * 단, 입력 특성이 반드시 표준화되어야 하고(평균은 0, 표준편차는 1) 모든 은닉층의 가중치는 Lecun 정규분포 초기화로 초기화되어야 함(<code>kernel_initializer=\"lecun_normal\"</code>). 또한, 네트워크는 일렬로 쌓은 층으로 구성되어야 하며 순환 신경망이나 스킵 연결(건너뛰어 연결된 층)과 같은 비 순차적 구조에는 사용하는 것이 힘듦.\n",
    "> 단, 일부의 경우 CNN에서도 SELU 사용 시 성능을 향상시킬 수도 있음.\n",
    "* 심층 신경망 은닉층에 사용할 활성화함수는 일반적으로 SELU > ELU > LeakyReLU(와 그 변종들) > ReLU > tanh > sigmoid 순으로 사용. 만약, 네트워크가 자기 정규화되지 못하면 ELU가 더 나을 수도 있고, 실행 속도가 중요하면 LeakyReLU가 더 좋을 수도 있음. 신경망이 과대적합되었다면 RReLU, 훈련세트가 아주 크다면 PReLU를 사용할 수 있음. 일반적으로는 ReLU가 가장 널리 사용되어왔으므로 대부분의 라이브러리와 하드웨어는 ReLU에 특화되어 있음. 즉, 속도가 중요하면 ReLU가 가장 좋은 선택."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "# LeakyReLU\n",
    "\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n",
    "\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAELCAYAAADECQ0AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAimElEQVR4nO3deXxU1d3H8c+PsAsCgiIKirhQcSlV6uOGpu5a17rVBYtWsW4FC1pFfZ5aKda6YUVR1JaKuOMu7jLFIkVBoRgEZLGAIIswQCAsSc7zx5mQkAxZJ3PmZr7v1+u+mMyZufc3Jzdf7pw5c6855xARkehqFLoAERGpGwW5iEjEKchFRCJOQS4iEnEKchGRiFOQi4hEnIJcRCTiFOQiIhGnIJc6MbNRZvZWA9pOIzN73Mx+MDNnZrn1vc1KaknLa05sq52ZLTOzvdOxvZoys5fMbGDoOjKV6Zud6WNmo4BfJWma7Jw7PNHewTl3+naeHwO+cs5dX+7+vsBw51yrlBZcvW23we9H8Shtp5Ltnw68AuQC84FVzrnN9bnNxHZjlHvd6XrNiW3di9/3Lq/vbSXZ9jHAIOBQYDfgcufcqHKPOQj4J7CXc25NumvMdI1DF5CFPgT6lLuv3oOivqTrjyqNf7z7AEudc5+maXvbla7XbGYtgSuBM9KxvSRaAV8BTyeWCpxzM8xsPnAp8Egaa4sEDa2k3ybn3PflllX1vVEzO8XMPjGz1Wa2yszeM7P9y7SbmQ00s2/MbJOZLTazuxNto4BjgesSww3OzLqWtJnZW2bWL/HWPKfcdp81szeqU0d1tlNmPc3MbFhimxvN7N9mdnSZ9piZPWpmQ81spZktN7P7zGy7+3xi+w8CeyS2/W2ZdQ0v/9iSeqqzrdr0b01fc21fN3Aa4ICJSfrkUDP7yMwKzGyumR1jZheYWYXH1pZzbpxzbrBz7mWguJKHvgFclKrtNiQK8uyxAzAMOAw/bLAGeNPMmibahwJ3AHcDBwDnA4sSbf2BScDfgU6JpaStxEtAG+DEkjvMrBVwFvBMNeuoznZK/AW4ELgC+AkwA3jXzDqVecwlQCFwJHA9MCDxnO3pD/wRWJzY9k8reWx5VW2rrv0L1XvN1amlvN7AVFdunNXMfgp8AowHDgb+DdwJ3JZ4LZR7/GAzy69i6V1JHVX5DDjMzFrUYR0Nk3NOS5oWYBT+Dyy/3HJPmfa3Knl+DD8WXv7+vkB+DWvZASgCjsa/td0I/KYW295aM35seXSZtkvxQd28OnXUYDs74IejLivTngPMA4aUWc+kcuv4AHiyin4ZBHxb1WsvV0+l26pt/9b0Ndf2dQOvAf9Icv8E4IUyP5+W+F2N3856dsIPTVW2tKii//OBvttpOxj/zmHvmuzr2bBojDz9JgD9yt0Xr++Nmp+NcBfwP8DO+HdjjYA98AHRDPiojpt5BviHmbV0zm3AHxmOdc5trGYd1bU30IQyQwHOuSIzmwT0KPO4/5R73hJglxpspyYq21YP6t6/1X3NVdWSTAtgWdk7zGxX/JH6z8rcvRn/u6pwNJ6oZxVQn8OEBYl/dURejoI8/TY45+bW8rlr8cMX5bXFH/lW5i38kMHVwHf4dwYzgaaVPamG3k6s9ywz+wg4ATg5zXWUHR7YkqStNsOJxYCVu69JuZ9Tta3aKD/1rKa1rATalbuv5POTKWXu6w7Mds79K9lKzGwwMLjyUjnVOfdJFY/Znp0S/66o5fMbLAV5tMwGTjMzc4n3mgmHJNqSMrP2wI+Aa51z4xP3HULp7/9rYBNwPPDNdlazGf9Wfrucc5vM7CX8kXgH4Hv8W/3q1lGt7eCHEzYDRyVuk/iQ9Qjg2SqeWxsr8OPWZf0Y+Laaz09F/9bna/4SPzxXVlv8fwBFiW21xo+Nf1/Jeh4DXqxiW9/VqkLvQOA759yyKh+ZZRTk6dcs8ba1rCLnXMlRxo5m1rNce9w59y0wAv/h1cNm9gR+3PU0/Cf5Z1ayzdX4o66rzGwRsDtwL/5oGOfcOjN7CLjbzDbhh3/aA4c650Yk1vEt/oOmrvhxzFXOuWQzDJ7BDyHsBTxX7jGV1lHd7Tjn1pvZCOAeM1sJLABuBDoCj1bSD7X1MTDMzM7E/4d5NdCFagZ5bfu33Drq8zW/l1hve+fcD4n7puHfhdxqZmPwv6elwD5mtq9zrsJ/SLUdWkl8KL5P4sdG+FlDPfG/+4VlHto7UauUF3qQPpsW/IdXLsmyuIr2l8us46f4nXkZfjhlMnB2NbZ9HH6u7sbEvydT5oMl/B/QLfgvwWzGz5r4U5nn74efWbEhUVPXMjW/VeZxhg8lBxxcizqqu51m+Nkvy/BHu/8m8YFpoj1GJR8eVtJPyT7sbIKfu7wysdxJxQ87K91Wbfq3pq+5jq97EnBdufsG49+NbATG4IdfJgIrUvx3kUvy/X5Umcc0x+/vh4f+O87ERd/sFBHM7BTgIaCHc64odD3lmdl1wFnOuZNC15KJNI9cRHDOvYt/19E5dC3bsQW4IXQRmUpH5CIiEacjchGRiFOQi4hEXJDphx06dHBdu3YNsemt1q9fzw477BC0hkyhvvBmz55NUVERPXqU/6JkdsrU/aKwEGbNgk2boF076Nat/reZKX0xderUlc65ncvfHyTIu3btypQpU6p+YD2KxWLk5uYGrSFTqC+83Nxc4vF48H0zU2TifrF5M5x8sg/xQw6BTz6Bli3rf7uZ0hdm9t9k92toRUQiwTm44QaIxaBTJ3j99fSEeBQoyEUkEh5+GEaOhObN4bXXoHOmTpQMQEEuIhnvvffgxhv97b/9DQ47LGw9mabOQW5mzc3sMzObbmZ5ZnZnKgoTEQH/weaFF0JxMdx+O1ykawRVkIoPOzcBxznn8s2sCfAvM3vHOffvFKxbRLLYqlVwxhmwZg384hdwpw4Tk6pzkDv/1dD8xI9NEou+LioidbJlC5x/PsydCz17wtNPQyMNBieVkumHifMiT8WfivIR59zkJI/pR+LKOB07diQWi6Vi07WWn58fvIZMob7w4vE4RUVF6ouE0PvFgw/uy8cf7067dpu59dapfP75pmC1hO6LKqX4dJRt8RdqPbCyxx166KEutPHjx4cuIWOoL7xjjz3W/fjHPw5dRsYIuV8MH+4cONesmXOTJgUrY6tM+RsBprgkmZrSNyrOuXgiyE9J5XpFJHt88AH07+9vP/UUHH542HqiIBWzVnY2s7aJ2y2AE4FZdV2viGSfOXPgggugqAhuvRUuuSR0RdGQijHyTvgrp+fg/2N40Tn3VgrWKyJZZPVqP0MlHoezz4YhQ0JXFB2pmLXyH+AnKahFRLJUYaE/Ep8zBw4+GEaP1gyVmlBXiUhwN94IH34Iu+wCb7wBrVqFrihaFOQiEtRjj8Hw4dC0Kbz6Kuy5Z+iKokdBLiLBfPwxXH+9v/3EE3DkkWHriSoFuYgE8c03cN55fobKzTfDZZeFrii6FOQiknbxuJ+hUjJTZejQ0BVFm4JcRNKqsNCfzXD2bDjoIBgzBnJyQlcVbQpyEUmrQYPg/fehQwc/Q6V169AVRZ+CXETS5okn4KGHoEkTP0Ml8DXYGwwFuYikRSwG117rbz/+OBx9dNByGhQFuYjUu3nz4Nxz/fj4wIFw+eWhK2pYFOQiUq/WrPEzU1atgp//HO65J3RFDY+CXETqTVGRv8bm11/DAQfAs89qhkp9UJCLSL256SZ45x1o397PUNlxx9AVNUwKchGpF089BQ8+CI0bwyuvQLduoStquBTkIpJyEybANdf42yNGwDHHhK2noVOQi0hKLVjgZ6hs2QIDBsCVV4auqOFTkItIyqxd62eorFwJp5wC994buqLsoCAXkZQoKoKLL4a8PNh/f3j+eT8+LvVPQS4iKXHLLfD227DTTvDmm9CmTeiKsoeCXETqbNQouO8+fwQ+dizsvXfoirKLglxE6mTiRLj6an/7kUcgNzdoOVlJQS4itfbtt3DOObB5M9xwA/TrF7qi7KQgF5FaWbcOzjwTVqyAk06CBx4IXVH2UpCLSI0VF8Oll8KMGdC9O7zwgmaohKQgF5EaGzzYnzulXTs/Q6Vt29AVZTcFuYjUyNNP+1PR5uTAyy/DvvuGrkgU5CJSbZMmwVVX+dsPPwzHHRe2HvEU5CJSLQsXwtln+xkq111XelIsCU9BLiJVys/3M1SWL4fjj/enp5XMoSAXkUoVF0OfPjB9uh8Pf+klaNIkdFVSloJcRCp1xx3w2mt+Zsqbb/qZKpJZ6hzkZtbFzMab2UwzyzOz/qkoTETCGzMGhg71M1RefNHPGZfMk4oj8kJgoHOuB3A4cJ2Z9UjBekUkoJkzW/PrX/vbw4bBiScGLUcqUecgd84tdc59kbi9Dvga2L2u6xWRcBYtgttvP4hNm+A3v/GzVCRzpXSM3My6Aj8BJqdyvSKSPuvXw1lnwerVTfnZz+CvfwWz0FVJZVJ2dgQzawWMBQY459Ymae8H9APo2LEjsVgsVZuulfz8/OA1ZAr1hRePxykqKsrqviguhjvvPIAvv9yZTp3W07//l0ycWBi6rOAy/W8kJUFuZk3wIT7GOfdKssc450YCIwF69erlcgOftDgWixG6hkyhvvDatm1LPB7P6r743/+FCRNgxx3h7rvzOOuso0OXlBEy/W+kzkFuZgY8BXztnNOJLEUi6vnn4a67oFEjfzbD5s03hC5JqikVY+RHAX2A48xsWmI5LQXrFZE0+ewzuPxyf/uBB+CUU8LWIzVT5yNy59y/AH0UIhJR333nz6GycaM/IdZvfxu6IqkpfbNTJItt2OBnqCxdCsceC8OHa4ZKFCnIRbKUc344ZepU6NbNn1u8adPQVUltKMhFstQf/+i/dt+6tb/aT4cOoSuS2lKQi2Shl16CP/zBz1B5/nk44IDQFUldKMhFsszUqfCrX/nb994Lp2mOWeQpyEWyyJIl/gIRBQVwxRVw442hK5JUUJCLZImCAj/NcMkS6N0bRozQDJWGQkEukgWc80fgn38OXbvC2LGaodKQKMhFssCf/uQ/1GzVyl/lZ+edQ1ckqaQgF2ngxo71l2szg+eegwMPDF2RpJqCXKQB+/JLuOwyf/uee+D008PWI/VDQS7SQC1d6meobNjgpxsOGhS6IqkvCnKRBmjjRjjnHFi8GI46Ch5/XDNUGjIFuUgD4xxceSVMngx77gmvvALNmoWuSuqTglykgfnzn2HMGNhhB38OlV12CV2R1DcFuUgD8tprMHiwH0YZMwYOPjh0RZIOCnKRBmL6dLj0Un976FB/nnHJDgpykQZg2TI44wxYvx769IHf/z50RZJOCnKRiCuZobJoERx+OIwcqRkq2UZBLhJhzkG/fjBpEnTp4sfImzcPXZWkm4JcJMLuvRdGj4aWLf0MlY4dQ1ckISjIRSLqjTfgllv87WeegZ49g5YjASnIRSJoxgy45BI/tDJkiB8jl+ylIBeJmOXL/QyV/Hy4+GI/b1yym4JcJEI2bYJf/AL++1847DB48knNUBEFuUhkOAe/+Q1MnAidO/sZKi1ahK5KMoGCXCQi7r8fRo3y4f3669CpU+iKJFMoyEUi4O234eab/e3Ro+GQQ8LWI5lFQS6S4fLy4KKL/NDKH/8I554buiLJNApykQy2cqWfobJuHVx4Idx+e+iKJBMpyEUy1ObN/uh7wQLo1Qv+/nfNUJHkUhLkZvY3M1tuZl+lYn0i2c45uPZamDABdtvNf7ipGSqyPak6Ih8FnJKidYlkvWHD4KmnSmeo7LZb6Iokk6UkyJ1zE4BVqViXSLZ7553SK96PGuWHVUQqozFykQwycyb88pdQXAz/939wwQWhK5IoaJyuDZlZP6AfQMeOHYnFYunadFL5+fnBa8gU6gsvHo9TVFQUrC/WrGnMtdceytq1LTj22OUcc8xMQv5atF+UyvS+SFuQO+dGAiMBevXq5XJzc9O16aRisRiha8gU6guvbdu2xOPxIH2xeTOcfDIsWeK/7DNu3C60bLlL2usoS/tFqUzvCw2tiATmHNxwA8Ri/mv3r7/uLxQhUl2pmn74HDAJ6G5mi83s16lYr0g2ePhhf53N5s39ibA6dw5dkURNSoZWnHMXpWI9Itnmvffgxhv97b/9zZ+aVqSmNLQiEsisWf5r98XF/qv3F+lwSGpJQS4SwKpV/hwqa9b4C0XceWfoiiTKFOQiabZlC5x/Psyd6y+Y/PTT0Eh/iVIH2n1E0qx/f/j4Y+jYEd54A3bYIXRFEnUKcpE0euQRGDECmjXzM1S6dAldkTQECnKRNPngA380Dv6EWIcfHrYeaTgU5CJpMGeOP29KURHceitccknoiqQhUZCL1LPVq/0MlXgczj4bhgwJXZE0NApykXq0ZYs/Ep8zBw4+2F84WTNUJNW0S4nUo9/9Dj78EHbZxc9QadUqdEXSECnIRerJY4/B8OHQtCm8+irsuWfoiqShUpCL1IOPP4brr/e3n3gCjjwybD3SsCnIRVLsm2/gvPP8DJWbb4bLLgtdkTR0CnKRFIrH/QyVkpkqQ4eGrkiygYJcJEUKC/3ZDGfPhoMOgjFjICcndFWSDRTkIikycCC8/z7svLOfodK6deiKJFsoyEVSYORI+OtfoUkTeOUV6No1dEWSTRTkInU0fjxcd52/PXIkHH102Hok+yjIRepg7lw/Q6WwEAYNgr59Q1ck2UhBLlJLa9bAmWf6q/2cfjr8+c+hK5JspSAXqYXCQvjlL+Hrr+GAAzRDRcJSkIvUwk03wbvvQocO8OabsOOOoSuSbKYgF6mhJ5+EYcNKZ6jstVfoiiTbKchFauCf/4RrrvG3H3sMevcOW48IKMhFqm3+fDj3XD8+/rvfwRVXhK5IxFOQi1TD2rX+3Ck//ACnngp/+UvoikRKKchFqlBUBBddBDNnwv77w3PPaYaKZBYFuUgVbr4Zxo2DnXbyM1TatAldkci2FOQilXjqKXjgAWjcGMaOhb33Dl2RSEUKcpHtmDChdIbKo49Cbm7QckS2S0EuksSCBX6GypYt0L8/XHVV6IpEtk9BLlJOyQyVlSvh5JPhvvtCVyRSuZQEuZmdYmazzWyumd2SinWKhOAcXHwx5OXBj34EL7zgx8dFMlmdd1EzywEeAU4EFgOfm9kbzrmZdV23SLotXdqC//xHM1QkWlJxrHEYMNc5Nx/AzJ4HzgK2G+SzZ88mN/AnR/F4nLZt2watIVOoL7zPPptGQQFALl26wJVXhq4oLO0XpTK9L1IR5LsDi8r8vBj4n/IPMrN+QD+AJk2aEI/HU7Dp2isqKgpeQ6ZQX8D69Y0TIQ6dO28ANpPlXaL9ooxM74u0jf4550YCIwF69erlpkyZkq5NJxWLxYK/K8gU2d4XeXkll2fLpUOHTSxaNCl0SRkh2/eLsjKlL8ws6f2p+LDzO6BLmZ87J+4TyXiLF8Mpp0A8Du3bw267FYQuSaTGUnFE/jmwr5nthQ/wXwIXp2C9IvVq9Wof4osXw1FHQaNGfuqhSNTU+YjcOVcIXA+8B3wNvOicy6vrekXqU36+nyuel+dPhPXGGz7IRaIoJWPkzrlxwLhUrEukvq1fDz//OUycCJ07+0u27bRT6KpEak/HIJJV1q/3V7yfMAF23x3Gj4c99ghdlUjdKMgla5QMp8Ri0KmTD/F99gldlUjd6cvHkhVWrvTDKZ99Brvu6kN8331DVyWSGjoilwZv4UI/T/yzz2DPPf0FlLt3D12VSOooyKVBy8vzUwtnz4aDDoJPP4X99gtdlUhqKcilwXrrLTjiCD9P/Oij/Qecu+0WuiqR1FOQS4PjnL/K/Zlnwrp1cOGF8P77kMHnPBKpEwW5NCj5+dCnD/z+9z7QhwzxV71v0SJ0ZSL1R7NWpMGYMQMuuABmzYIddoDRo+Gcc0JXJVL/dEQukeccPPkkHHaYD/EePfwMFYW4ZAsFuUTa99/7wL7qKti4Ea64Aj7/3Ie5SLZQkEtkvfACHHggvP467LgjPP00PPUUtGwZujKR9NIYuUTOwoXQvz+89pr/+cQT/dCKzpki2UpH5BIZW7b4aYX77+9DvFUreOwxeO89hbhkNx2RS8ZzDsaNg5tugq+/9vedfz488IA/Da1ItlOQS0b74gsYNMif5Apg771h+HB/ZR8R8TS0Ihlpxgx/1H3ooT7E27XzR+B5eQpxkfJ0RC4ZZdo0+NOf4OWX/c/NmsH118Ntt/kwF5GKFOQSXFERvP02PPigv+gD+AC/+mr/VXud6EqkcgpyCWbdOhg1Ch56CObN8/e1bg1XXunHxRXgItWjIJe0cs6fTvbvf/fDJ+vX+/u7doXf/hZ+/Wv/5R4RqT4FuaTFggXwzDP+CHz+/NL7e/f2X+45+2zIyQlVnUi0Kcil3syZ44+6x4710whLdO4Ml10GffvqupkiqaAgl5QpLITJk+Hdd/03L7/6qrStVSt/Bfu+feH443X0LZJKCnKpk4UL4YMPfHh/8AGsWVPa1qaNv0rPuefCSSfp4g4i9UVBLtXmnL+I8Sef+A8sJ0zwQV7Wvvv6L+yceqo/8m7aNEytItlEQS5JOecvWjxlSukydSr88MO2j2vbFo45xof3ySdDt25ByhXJagpyYePGRnzxhf/6+8yZMH26D+3lyys+tmNHH9wly4EHQiOd6EEkKAV5ltiyBRYt8lP/5s+HuXP9mQTz8uDbb3vjXMXntGsHvXptu3TpAmbpr19Etk9B3kDk58N338GSJX5ZuLA0tOfP9yFeVJT8uTk5ju7djR494IAD/HLoobDXXgptkShQkGeo4mKIx/2Y9MqV2y4rVsDSpT6wS8J73brK12fmj6a7dfPLXnv5CzQccAB8990nnHDCsWl5XSKSenUKcjM7H/gDsD9wmHNuSiqKirqiIigogA0bfMCuXeun5VX175o1pcH9ww8+zKureXN/bpLdd/f/du5cGtrdusGee/oTUSWzbFmScRURiYy6HpF/BfwCeDwFtdRIcbEPzJKlsLDiz1u2wObNyZcpU3Zi9erKH1OyFBSUBvOGDVXf3rw5Na+xTRvo0KHi0r49dOq0bXC3bathEJFsVacgd859DWA1TJAvv5xNq1a5OMfWD9latryAVq2uZcuWDaxcedrWtpIlJ6cvZn0pLFxJcfF5SdZ6DXAhsAjok6R9IHAGMBu4Okn77cAJwDRgQJL2ocCRwKfA4CTtw4CewIfAEBo18rM5Gjf232Lcf//H2XXX7qxb9ybffHM/OTmlbY0bw6BBo9lnny58/vkLvPLKCJo02TaYR416mQ4dOjBq1ChGjRpVYevjxo2jZcuWPProo7z44osV2mOJ88Ped999vPXWW9u0FRQUMHnyZADuuusuPvroo23a27dvz9ixYwG49dZbmTRp0jbtnTt35plnngFgwIABTJs2bZv2/fbbj5EjRwLQr18/5syZs017z549GTZsGACXXnopixcv3qb9iCOO4O677wbg3HPP5YdycyCPP/547rjjDgBOPfVUCgoKtmk//fTTGTRoEAC5ubmUd8EFF3DttddSXFzM3LlzKzymb9++9O3bl5UrV3LeeRX3vWuuuYYLL7yQRYsW0adPxX1v4MCBnHHGGcyePZurr664791+++2ccMIJTJs2jQEDBlRoHzp0KEceeSSffvopgwdX3PeGDRtGz549+fDDDxkyZEiF9scff5zu3bvz5ptvcv/991doHz16NF26dOGFF15gxIgRW++Px+O0bduWl1+uv32vRYsWvPPOO0B273sbNmzgtNNOq9Be1b5XIm1j5GbWD+jnf2q19ax3JQoKKs5RLmt7www+7BxNmhTRtOkWYAsbNzrAYebD1MzRrl0B7dqtobBwLUuWFAIu0ebb99nnBzp1WkJ+/jK++moTZi7RBo0aOXr3XkjXru1YsWI+48evp1Ejt3XdjRo5rrhiGj/6UT55edN5/vl4hTpvuGEye+yxlE8/nUE8XrG9detJODePtWvz2LChYvvEiRNp06YNs2bNSvr8CRMm0Lx5c+bMmZO0veSPad68eRXac3JytrYvWLCgQntxcfHW9oULF1Zob9Kkydb2xYsXV2hfsmTJ1vYlS5ZUaF+8ePHW9mXLllVoX7hw4db2FStWsHbt2m3aFyxYsLV91apVbNq0aZv2efPmbW1P1jdz5swhFosRj8dxzlV4zKxZs4jFYqxZsybp8/Py8ojFYixfvjxp+4wZM2jdunXSvgOYPn06jRs3Zu7cuUnbv/jiCzZv3sxXX32VtH3KlCnE43GmT5+etH3y5MksXbqUGTOS73uTJk1i3rx55OXlbdNeVFREPB6v132voKAgEvtefn5+ve57GzduTNpe1b5XwlyyeWdlH2D2IbBrkqbbnHOvJx4TAwZVd4y8R49e7tlnp5CTQ6VLyRFrsqWuc5djsVjS/yGzkfrCy83NJR6PVziqy1baL0plSl+Y2VTnXK/y91d5RO6cOyHVxbRsCT17pnqtIiLZSd/JExGJuDoFuZmdY2aLgSOAt83svdSUJSIi1VXXWSuvAq+mqBYREakFDa2IiEScglxEJOIU5CIiEacgFxGJOAW5iEjEKchFRCJOQS4iEnEKchGRiFOQi4hEnIJcRCTiFOQiIhGnIBcRiTgFuYhIxCnIRUQiTkEuIhJxCnIRkYhTkIuIRJyCXEQk4hTkIiIRpyAXEYk4BbmISMQpyEVEIk5BLiIScQpyEZGIU5CLiEScglxEJOIU5CIiEacgFxGJOAW5iEjEKchFRCJOQS4iEnF1CnIzu9fMZpnZf8zsVTNrm6K6RESkmup6RP4BcKBz7mBgDnBr3UsSEZGaqFOQO+fed84VJn78N9C57iWJiEhNpHKM/ArgnRSuT0REqqFxVQ8wsw+BXZM03eacez3xmNuAQmBMJevpB/QD6NixI7FYrDb1pkx+fn7wGjKF+sKLx+MUFRWpLxK0X5TK9L4w51zdVmDWF7gaON45t6E6z+nVq5ebMmVKnbZbV7FYjNzc3KA1ZAr1hZebm0s8HmfatGmhS8kI2i9KZUpfmNlU51yv8vdXeURexUpPAW4Gjq1uiIuISGrVdYx8ONAa+MDMppnZYymoSUREaqBOR+TOuX1SVYiIiNSOvtkpIhJxCnIRkYhTkIuIRFydpx/WaqNmK4D/pn3D2+oArAxcQ6ZQX5RSX5RSX5TKlL7Y0zm3c/k7gwR5JjCzKcnmY2Yj9UUp9UUp9UWpTO8LDa2IiEScglxEJOKyOchHhi4gg6gvSqkvSqkvSmV0X2TtGLmISEORzUfkIiINgoIcMLOBZubMrEPoWkLRZfv8SeDMbLaZzTWzW0LXE4qZdTGz8WY208zyzKx/6JpCM7McM/vSzN4KXUsyWR/kZtYFOAlYGLqWwLL6sn1mlgM8ApwK9AAuMrMeYasKphAY6JzrARwOXJfFfVGiP/B16CK2J+uDHHgQfyrerP6wQJft4zBgrnNuvnNuM/A8cFbgmoJwzi11zn2RuL0OH2C7h60qHDPrDPwceDJ0LduT1UFuZmcB3znnpoeuJcNk42X7dgcWlfl5MVkcXiXMrCvwE2By4FJCGoY/2CsOXMd21ek0tlFQ2aXqgMH4YZWskKrL9kl2MLNWwFhggHNubeh6QjCz04HlzrmpZpYbuJztavBB7pw7Idn9ZnYQsBcw3czADyV8YWaHOee+T2OJabO9viiRuGzf6fjL9mXbUNN3QJcyP3dO3JeVzKwJPsTHOOdeCV1PQEcBZ5rZaUBzYEcze8Y5d2nguraheeQJZvYt0Ms5lwknxkm7xGX7HsBftm9F6HrSzcwa4z/kPR4f4J8DFzvn8oIWFoD5I5t/AKuccwMCl5MxEkfkg5xzpwcupYKsHiOXbWT1ZfsSH/ReD7yH/3DvxWwM8YSjgD7AcYl9YVriiFQylI7IRUQiTkfkIiIRpyAXEYk4BbmISMQpyEVEIk5BLiIScQpyEZGIU5CLiEScglxEJOL+HzT4EGQ7Iqm1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ELU\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LeakyReLU를 사용하려면 LeakyReLU층을 만들고, 모델에서 적용하려는 층 뒤에 추가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # ...\n",
    "    keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2)\n",
    "    # ...\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PReLU를 사용하려면 <code>LeakyReLU</code> 부분을 PReLU로 바꿈. Keras에서는 공식적인 구현은 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SELU를 사용하려면 층을 만들 때 <code>activation=\"selu\", kernel_initalizer=\"lecun_normal\"</code> 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ELU나 다른 ReLU 변종과 함께 He 초기화를 사용하면 훈련 초기화 단계에서는 gradient문제를 감소시킬 수 있음.\n",
    "* 하지만, 훈련하는 동안 다시 발생하지 않으리라는 보장은 없음.\n",
    "* 이를 위해 배치 정규화(Batch normalization) 방법 사용.\n",
    "  * 각 층에서 활성화 함수를 통과하기 전이나 후에 연산을 하나 추가함.\n",
    "  * 입력을 원점에 맞추고 정규화한 뒤, 각 층에서 두 개의 새로운 파라미터로 결과값의 스케일을 조절하고 이동시킴. 한 파라미터는 스케일 조정에, 나머지 하나는 이동에 사용함.\n",
    "* 신경망의 첫 번째 층으로 배치 정규화를 추가하면 훈련 세트를 StandardScaler 등을 사용해 표준화할 필요가 없음.\n",
    "* 입력 데이터를 원점에 맞추고 정규화하기 위해 평균과 표준편차를 추정해야 함. 이를 위해 현재 미니배치에서 입력의 평균과 표준편차를 평가함.\n",
    "$$ \\boldsymbol{\\mu}_B=\\frac{1}{m_B}\\sum_{i=1}^{m_B}\\mathbf{X}^{(i)} $$\n",
    "$$ \\boldsymbol{\\sigma}_B^2=\\frac{1}{m_B}\\sum_{i=1}^{m_B}\\left(\\mathbf{x}^{(i)}-\\boldsymbol{\\mu}_B\\right)^2 $$\n",
    "$$ \\hat{\\mathbf{x}}^{(i)}=\\frac{\\mathbf{x}^{(i)}-\\boldsymbol{\\mu}_B}{\\sqrt{\\boldsymbol{\\sigma}_B^2+\\epsilon}} $$\n",
    "$$ \\mathbf{z}^{(i)}=\\gamma\\otimes\\hat{\\mathbf{x}}^{(i)}+\\boldsymbol{\\beta} $$\n",
    "  * $\\boldsymbol{\\mu}_B$ : 미니배치 B에 대한 입력의 평균 벡터\n",
    "  * $\\boldsymbol{\\sigma}_B$ : 미니배치에 대한 입력의 표준편차 벡터\n",
    "  * $ m_B$ : 미니배치 내의 샘플 수\n",
    "  * $\\hat{\\mathbf{x}}^{(i)}$ : 평균이 0이고 정규화된 샘플 i의 입력\n",
    "  * $\\gamma$ : 층의 출력 스케일 파라미터 벡터. $\\gamma$와 $\\boldsymbol{\\beta}$의 차원은 모두 $\\mathbf{z}^{(i)}$와 동일. (각 층의 뉴런마다 $\\gamma$와 $\\boldsymbol{\\beta}$를 가진다는 의미.)\n",
    "  * $\\otimes$ : 원소별 곱셈\n",
    "  * $\\boldsymbol{\\beta}$ : 층의 출력 이동 파라미터 벡터. 각 입력은 해당 파라미터만큼 이동\n",
    "  * $\\epsilon$ : 분모가 0이 되는 것을 막기 위한 작은 숫자. 안전을 위한 항(smoothing term)이라고 함. 주로 10^-5.\n",
    "  * $\\mathbf{z}^{(i)}$ : 배치 정규화 연산의 출력. 즉, 입력의 스케일을 조정하고 이동시킨 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련하는 동안 입력을 정규화한 다음 스케일을 조정하고 이동시킴.\n",
    "* 단, 테스트 시에는 여러 샘플로 이루어진 배치가 아닌 하나의 샘플에 대한 예측을 만들어야 하므로 테스트 시의 입력의 평균과 표준편차를 사용할 수 없음.\n",
    "  * 배치를 사용하더라도 그 크기가 매우 작거나 독립 동일 분포 조건을 만족하지 못할 수 있음.\n",
    "* 하나의 방법은 훈련이 끝난 후 전체 훈련 세트를 신경망에 통과시켜 배치 정규화 층의 각 입력에 대한 평균과 표준편차를 계산하는 것이 있음. 예측 시 사용한 평균과 표준편차를  최종 입력 평균과 표준편차를 대신 사용할 수 있음.\n",
    "* <code>BatchNormalization</code>층은 층의 입력 평균과 표준편차의 이동 평균을 사용해 훈련하는 동안 최종 통계를 추정.\n",
    "  * $\\boldsymbol{\\gamma}, \\boldsymbol{\\beta}$는 일반적인 역전파를 통해 학습되고, $\\boldsymbol{\\mu}(최종\\;입력\\;평균\\;벡터), \\boldsymbol{\\sigma}(최종\\;입력\\;표준편차\\;벡터$는 지수 평균 이동을 사용해 추정됨. 또한, 훈련하는 동안에 추정되지만 훈련이 끝난 후에 위의 식에서 평균과 표준편차를 대체하기 위해 사용됨.\n",
    "* 배치 정규화는 모델의 성능을 크게 향상시킴.\n",
    "  * 그레이디언트 소실 문제가 크게 감소해 tanh나 sigmoid도 사용 가능.\n",
    "  * 가중치 초기화에 네트워크가 훨씬 덜 민감해짐.\n",
    "  * 규제와 같은 역할을 하여 다른 규제의 필요성을 줄여줌.\n",
    "* 단, 배치 정규화는 모델의 복잡도를 키우고, 실행 시간이 느려짐.\n",
    "  * 훈련이 끝난 후 이전 층과 배치 정규화 층을 합쳐 실행 속도 저하를 피할 수 있음. 이전 층의 가중치를 바꿔 스케일이 조정되고 이동된 출력을 만듦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras에서의 사용은 은닉층의 활성화 함수 전이나 후에 BatchNormalization층을 추가하면 됨.\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 배치 정규화 층은 입력마다 4개의 파라미터 $\\boldsymbol{\\gamma}, \\boldsymbol{\\beta}, \\boldsymbol{\\mu}, \\boldsymbol{\\sigma}$를 추가함(ex. 첫 번째 배치 정규화 층에서는 4*784=3136개의 파라미터 존재)\n",
    "> * $\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}$는 역전파로 학습되지 않기 때문에 Non-trainable params로 분류."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번재 배치 정규화 층.\n",
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 정규화 층은 활성화 함수 이후보다 활성화 함수 이전에 추가하는 것이 좋다고 알려짐. 활성화 함수 이전에 배치 정규화 층을 추가하려면, 은닉층(Dense)에서 활서오하 함수를 지정하지 않고, 배치 정규화 층 뒤에 별도의 층으로 활성화 함수를 추가해야 함.\n",
    "* 배치 정규화 층은 입력마다 이동 파라미터를 포함하기 때문에 이전 층에서 편향을 뺄 수 있음.(<code>use_bias=False</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <code>BatchNormalization</code>에 조정할 하이퍼파라미터는 기본값으로도 보통 잘 동작하지만, <code>momentum</code> 매개변수(지수 이동 편균을 업데이트할 때 사용하는 값. $\\hat{\\mathbf{v}}\\leftarrow \\hat{\\mathbf{v}}\\times\\text{momentum}+\\mathbf{v}\\times(1-\\text{momentum})$ )는 조정하기도 함. 일반적으로는 1에 가까운 값.\n",
    "  * 데이터셋이 크고 미니배치가 크면 모멘텀 값을 0.99...9와 같이 9를 더 넣어 1에 더 가깝게 만듦.\n",
    "* <code>axis</code>매개변수는 정규화할 축을 결정. 기본값은 -1. (다른 축을 따라 계산한 평균과 표준편차를 이용해 마지막 축을 정규화함.)\n",
    "  * 입력 배치가 2차원(샘플 개수*특성 개수)이라면 각 입력 특성이 배치 내의 모든 샘플에 대해 계산한 평균과 표준편차를 기준으로 정규화.\n",
    "  * 위의 예시에서 첫 번쨰 배치 정규화 층은 784개의 입력 특성마다 독립정으로 정규화됨. 배치 정규화 층을 Flatten층 이전으로 옮기면 입력 배치는 샘플 개수\\*높이\\*너비 크기의 3차원이 되므로 배치 정규화 층은 28개의 평균과 28개의 표준편차 계산하고 동일한 평균과 표준편차를 이용해 모든 픽셀을 정규화함.\n",
    "* 배치 정규화는 훈련하는 동안에는 배치 통계를 사용하고, 훈련이 끝난 뒤에는 최종 통계를 사용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내부 코드\n",
    "\n",
    "class BatchNormalization(keras.layers.layer):\n",
    "    # ...\n",
    "    def call(self, inputs, training=None):\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * call 내에서 실제 계산 수행. fit()은 훈련하는 동안 call의 training 매개변수를 1로 설정. 훈련과 테스트에 대해 다르게 동작하는 층을 만들려면 call()에 training 매개변수를 추가하여 어떤 것을 계산할 지 결정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 정규화가 널리 사용되면서 거의 모든 층 뒤에 배치 정규화를 사용하고, 신경망 그림에는 이를 제외해서 그리는 경우도 많음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그레이디언트 폭주 문제를 완화하는 또 다른 방법은 역전파될 때 일정 임곗값을 넘지 못하게 gradient를 잘라내는 방법이 있고, 이를 그레이디언트 클리핑(gradient clipping)이라고 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * gradient 벡터의 모든 원소를 -1.0과 1.0 사이로 클리핑. 즉, 훈련되는 각 파라미터에 대한 손실의 모든 편미분 값을 -1.0에서 1.0으로 잘라냄.\n",
    "* 임곗값은 하이퍼파라미터로 튜닝 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 훈련된 층 재사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 큰 규모의 신경망을 새로 훈련하는 것은 힘드므로, 해결하려는 것과 비슷한 유형의 문제를 처리한 신경망이 이미 있다면 해당 신경망의 하위층을 재사용하는 것이 좋고, 이를 전이 학습(transfer learning)이라고 함.\n",
    "  * 훈련 속도를 높여주고 필요한 훈련 데이터도 줄여줌.\n",
    "  * ex) 카테고리 100개로 구분된 이미지를 분류하도록 훈련된 DNN이 있고, 자동차 종류를 구체적으로 분류하는 DNN을 만들려고 할 때, 카테고리 분류 DNN의 하위 층 일부를 재사용하는 것이 좋을 수 있음.\n",
    "  * 새로운 작업에 유용한 고수준 특성은 원본 작업의 특성과는 다르므로 상위 은닉층은 하위 은닉층보다는 덜 유용함.\n",
    "  * 작업이 비슷할 수록 가져올 하위 층의 개수를 늘리는 것이 좋음.\n",
    "* 전이 학습을 사용하려면 재사용하려는 층을 모두 동결(경사 하강법으로 가중치가 바뀌지 않도록 훈련되지 않는 가중치로 만듦)하고 모델을 훈련한 뒤 성능을 평가함. 그 뒤, 맨 위에 있는 한 두개의 은닉층의 동결을 해제하고 역전파를 통해 가중치를 조절하여 성능이 향상되는지 확인.\n",
    "  * 훈련 데이터가 많다면 동결 해제할 층을 늘릴 수 있음.\n",
    "  * 재사용하는 층의 동결을 해제할 때는 학습률을 줄여 가중치를 세밀하게 튜닝하는 게 좋음.\n",
    "  * 여전히 성능이 좋지 않거나 훈련 데이터가 적다면 상위 은닉층을 제거하고 남은 은닉층을 다시 동결하는 식으로 재사용할 은닉층의 적절한 개수를 찾을 때 까지 반복할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ex) fashion_mnist 데이터셋 훈련\n",
    "  * model A(model_fashion)은 \"Sandal\", \"Shirt\" 레이블이 붙은 데이터를 제외하고 훈련시킨 모델. model B는 \"Sandal\", \"Shirt\"를 구분하느 모델(shirt면 양성, sandal이면 음성)\n",
    "  * model A의 은닉층을 재사용하여 model B에 사용\n",
    "  * model B의 훈련 데이터셋은 200개만 존재.\n",
    "* **참고만 할 것**. 이유 후술"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashoin_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashoin_mnist.load_data()\n",
    "\n",
    "# model A에 쓸 데이터셋 준비\n",
    "X_train_removed = X_train_full[np.logical_and(y_train_full!=5, y_train_full!=6)] / 255.0\n",
    "y_train_removed = y_train_full[np.logical_and(y_train_full!=5, y_train_full!=6)]\n",
    "X_test_removed = X_test[np.logical_and(y_test!=5, y_test!=6)] / 255.0\n",
    "y_test_removed = y_test[np.logical_and(y_test!=5, y_test!=6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model B에 쓸 데이터셋 준비\n",
    "X_train_forB = X_train_full[np.logical_or(y_train_full==5, y_train_full==6)] / 255.0\n",
    "y_train_forB = y_train_full[np.logical_or(y_train_full==5, y_train_full==6)]\n",
    "X_test_forB = X_test[np.logical_or(y_test==5, y_test==6)] / 255.0\n",
    "y_test_forB = y_test[np.logical_or(y_test==5, y_test==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model B에 쓸 데이터셋 중, 200개만 사용.\n",
    "X_train_forB = X_train_forB[:200]\n",
    "y_train_forB = y_train_forB[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train_forB)):\n",
    "    if y_train_forB[i] == 5:\n",
    "        y_train_forB[i]=0\n",
    "    else:\n",
    "        y_train_forB[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test_forB)):\n",
    "    if y_test_forB[i] == 5:\n",
    "        y_test_forB[i]=0\n",
    "    else:\n",
    "        y_test_forB[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train_removed)):\n",
    "    if y_train_removed[i]>=7:\n",
    "        y_train_removed[i]-=2\n",
    "        \n",
    "for i in range(len(y_test_removed)):\n",
    "    if y_test_removed[i]>=7:\n",
    "        y_test_removed[i]-=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_removed[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model A\n",
    "model_fashion = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(8, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 808       \n",
      "=================================================================\n",
      "Total params: 266,408\n",
      "Trainable params: 266,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fashion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fashion.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4984 - accuracy: 0.8432\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3178 - accuracy: 0.8927\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2901 - accuracy: 0.9030\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2725 - accuracy: 0.9092\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2606 - accuracy: 0.9136\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2509 - accuracy: 0.9170\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2414 - accuracy: 0.9190\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2342 - accuracy: 0.9213\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2275 - accuracy: 0.9229\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2220 - accuracy: 0.9246\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2166 - accuracy: 0.9258\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2106 - accuracy: 0.9287\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2051 - accuracy: 0.9305\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2005 - accuracy: 0.9320\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1968 - accuracy: 0.9326\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1928 - accuracy: 0.9344\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1875 - accuracy: 0.9348\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1840 - accuracy: 0.9373\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1795 - accuracy: 0.9381\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1765 - accuracy: 0.9394\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1729 - accuracy: 0.9410\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9416\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9424\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1617 - accuracy: 0.9441\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1593 - accuracy: 0.9449\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1560 - accuracy: 0.9463\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1537 - accuracy: 0.9466\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1517 - accuracy: 0.9474\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1476 - accuracy: 0.9486\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1452 - accuracy: 0.9484\n"
     ]
    }
   ],
   "source": [
    "history = model_fashion.fit(X_train_removed, y_train_removed, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20669692754745483, 0.9269999861717224]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model A의 정확도는 약 93%\n",
    "model_fashion.evaluate(X_test_removed, y_test_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 모델 복제 및 가중치 복사\n",
    "\n",
    "model_A = keras.models.clone_model(model_fashion)\n",
    "model_A.set_weights(model_fashion.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 층을 제외한 모든 층 재사용 및 새로운 출력층 추가.\n",
    "\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업 B(셔츠, 샌들 분류)를 위해 훈련. 단, 새로운 출력층이 랜덤하게 초기화되어있으므로, 큰 오차 그레이디언트가 재사용된 가중치를 망칠 수 있음. 따라서 처음 몇 번의 epoch동안에는 재사용된 층을 동결하고 새로운 층에게 적절한 가중치를 학습할 시간을 줌.\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 층을 동결하거나 동결을 해제했다면 그 다음에는 반드시 모델을 컴파일해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9950\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9950\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9950\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonenv\\mlenv\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9950\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9950\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9950\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9950\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9950\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9950\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9950\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9950\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9950\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9950\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9950\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9950\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9950\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9950\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9950\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9950\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9950\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9950\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9950\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "# 몇 에포크 동안 모델을 훈련한 뒤, 재사용된 층의 동결을 해제하고 훈련을 계속함.\n",
    "# 동결 해제 이후에는 학습률을 낮춰 재사용된 가중치가 망가지는 것을 막아주는 게 좋음.\n",
    "\n",
    "history = model_B_on_A.fit(X_train_forB, y_train_forB, epochs=10)\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "optimizer = keras.optimizers.SGD(lr=1e-4)   #기본값은 1e-2\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_forB, y_train_forB, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06825259327888489, 0.9959999918937683]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 99.6%\n",
    "model_B_on_A.evaluate(X_test_forB, y_test_forB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 단, 위의 예시는 높은 성능을 가진 모델을 찾기 까지 여러 설정을 시도해 본 것이므로, 타깃 클래스나 랜덤 초깃값을 바꾸면 성능이 떨어지게 됨.(즉, 위처럼 해야만 성능이 높게 나오는 것이고, 위의 예시는 참고용으로만 제작.)\n",
    "> * 논문들에서 신경망을 다룰 때 결과가 너무 긍정적인 이유는 주로 가장 좋은 결과만을 표시하기 때문이므로 주의해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전이 학습은 작은 완전 연결 네트워크에는 잘 동작하지는 않음.\n",
    "* 주로 일반적인 특성을 감지하는 경향이 있는 심층 합성곱 신경망에서 잘 동작함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블된 훈련 데이터가 많지 않은 경우에, 비슷한 작업에 대한 훈련된 모델도 없는 경우, 비지도 사전훈련(unsupervised pretraining)을 사용할 수 있음.\n",
    "  * 레이블이 없는 데이터를 모으는 것은 쉽지만, 이에 레이블을 부여하는 작업은 많은 비용이 듦.\n",
    "  * 레이블되지 않은 훈련 데이터를 많이 모을 수 있다면 이를 이용해 autoencoder, 생성적 적대 신경망과 같은 비지도 학습 모델을 훈련할 수 있음. 이후 해당 모델의 하위층을 재사용하고, 그 위에 새 작업에 맞는 출력층을 추가해 지도 학습으로 최종 네트워크를 세밀하게 튜닝하는 방법을 사용할 수 있음.\n",
    "* 딥러닝 초기에는 탐욕적 층 단위 사전훈련(greedy layer-wise pretraining) 사용. 하나의 층을 가진 비지도 학습 모델을 훈련한 뒤, 이 층을 동결하고 새 층을 추가한 뒤 다시 훈련. 이후 층을 동결하고 새 층을 추가하여 훈련하는 작업을 반복한 뒤 최종적으로 지도 학습을 진행."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블된 훈련 데이터가 많지 않은 경우 또 다른 방법은 레이블된 훈련 데이터를 쉽게 얻거나 생성할 수 있는 보조 작업에서 첫 번째 신경망을 훈련한 뒤, 해당 신경망의 하위 층을 재사용하는 방법이 있음.\n",
    "  * ex) 얼굴 인식 시스템을 만들려고 하는데 개인별 이미지가 얼마 없다면, 인터넷에서 무작위로 많은 인물의 이미지를 수집해 두 개의 다른 이미지가 같은 사람의 것인지 감지하는 첫 번째 신경망을 훈련할 수 있고, 해당 신경망은 얼굴의 특성을 잘 감지할 것이므로 하위 신경망을 재사용해 적은 훈련 데이터에서도 얼굴을 잘 구분하는 분류기를 훈련할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고속 optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 심층 신경망의 훈련 속도는 매우 느릴 수 있으므로, 표준적인 경사 하강법 optimizer대신 더 빠른 optimizer를 사용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 완만한 경사를 굴러가는 공이 있다면, 처음에는 느리게 출발하지만, 종단속도에 도달할 때 까지는 빠르게 가속될 것임.\n",
    "* 이러한 원리를 적용한 것이 모멘텀(Momentum).\n",
    "  * 일반적인 경사 하강법은 경사면을 따라 일정한 크기의 step으로 조금씩 내려가므로 맨 아래에 도착하는 데 더 오랜 시간이 걸림.\n",
    "  * 일반적인 경사 하강법은 가중치에 대한 비용 함수 $J(\\boldsymbol{\\theta})$의 gradient $\\nabla_{\\theta}J(\\boldsymbol{\\theta})$에 대해 학습률 $\\eta$를 곱한 것을 빼 가중치 $\\boldsymbol{\\theta}$를 갱신함($\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}-\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$). 즉, gradient가 매우 작으면 속도도 매우 느려짐.\n",
    "* 모멘텀 최적화는 이전의 gradient가 얼마였는지를 고려하여, 매 반복에서 현재 gradient에 학습룰 $\\eta$를 곱한 후, 모멘텀 벡터(momentum vector) $\\mathbf{m}$에 더하고, 이 값을 빼는 방식으로 가중치를 계산.\n",
    "  * 일반적인 경사 하강법은 gradient를 속도로 사용하고, 모멘텀은 가속도로 사용함.\n",
    "* 일종의 마찰저항을 표현하고, 모멘텀이 너무 커지는 것을 막기 위해 모멘텀(momentum)이라는 하이퍼파라미터 $\\beta$를 사용.\n",
    "  * 보통 0(높은 마찰저항)~1(마찰저항 없음)사이로 설정되고, 일반적으로는 0.9 사용.\n",
    "$$1.\\;\\mathbf{m}\\leftarrow\\beta\\mathbf{m}-\\eta\\nabla_{\\theta}\\cdot J(\\boldsymbol{\\theta})$$\n",
    "$$2.\\;\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\mathbf{m}$$\n",
    "* gradient가 일정하면 종단속도(가중치를 갱신하는 최대 크기)는 $\\eta$를 곱한 gradient에 $\\frac{1}{1-\\beta}$를 곱한 것과 같음.\n",
    "  * ex) $\\beta=0.9$라면 종단속도는 gradient\\*학습률\\*10이 되므로, 일반적인 경사 하강법보다 10배 빠르다는 의미.\n",
    "* 더 빠르게 평탄한 지역을 탈출하도록 도움.\n",
    "* 배치 정규화를 사용하지 않는 DNN에서 상위층은 종종 스케일이 매우 다른 입력을 받게 되는데, 모멘텀 최적화를 사용하면 이러한 경우에 큰 도움이 됨.\n",
    "* 지역 최적점을 건너뛰는 데 도움이 됨.\n",
    "* 모멘텀 때문에 optimizer가 최적값에 도달하기 전까지 진동하듯이 움직이는데, 이 때문에 마찰저항이 조금 있는 것이 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonenv\\mlenv\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# keras에서의 모멘텀 사용. 단순히 SGD optimizer에 momentum 매개변수 지정.\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 튜닝할 하이퍼파라미터가 하나 더 늘어나지만, 웬만한 경우 <code>moemntum=0.9</code>에서 잘 작동하며 경사 하강법보다 거의 항상 빠름."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네스테로프 가속 경사(Nesterov accelerated gradient, NAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모멘텀 최적화의 한 변종.\n",
    "* 현재 위치가 $\\boldsymbol{\\theta}$가 아닌, 모멘텀의 방향으로 조금 앞선 $\\boldsymbol{\\theta}+\\beta\\mathbf{m}$에서 비용 함수의 gradient 계산.\n",
    "$$1.\\;\\mathbf{m}\\leftarrow\\beta\\mathbf{m}-\\eta\\nabla_{\\theta}\\cdot J(\\boldsymbol{\\theta+\\beta\\mathbf{m}})$$\n",
    "$$2.\\;\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\mathbf{m}$$\n",
    "* 일반 모멘텀 방식보다 네스테로프 방식이 최적값에 조금 더 가까워지고, 모멘텀보다 더 빨리 최적점에 도달할 수 있음.\n",
    "  * 진동을 감소시키고 수렴을 빠르게 만들어 줌\n",
    "* SGD optimizer를 만들 떄 <code>use_nesterov=True</code>로 설정하여 사용 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 한쪽이 길쭉한 그릇 형태에서, 경사 하강법은 전역 최적점 방향으로 바로 향하지 않고, 가장 가파른 경사를 따라 내려가기 시작해 골짜기 아래로 느리게 이동함.\n",
    "* 이를 일찍 감지하여 전역 최적점 쪽으로 좀 더 정확한 뱡향을 잡게 하는 알고리즘.\n",
    "  * 가장 가파른 차원을 따라 gradient 벡터의 스케일을 감소시킴.\n",
    "$$1.\\;\\mathbf{s}\\leftarrow\\mathbf{s}+\\nabla_{\\theta}J(\\boldsymbol{\\theta})\\otimes\\nabla_{\\theta}j(\\boldsymbol{\\theta})$$\n",
    "$$2.\\;\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}-\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\oslash\\sqrt{\\mathbf{s}+\\epsilon}$$\n",
    "  * $\\oplus$ : 원소 별 곱셈\n",
    "  * $\\oslash$ : 원소 별 나눗셈\n",
    "  * 1 : gradient의 제곱을 벡터 $\\mathbf{s}$에 누적함. 즉, $\\mathbf{s}$의 각 원소 $s_i$마다 $s_i\\leftarrow s_i+(\\partial J(\\boldsymbol{\\theta})/\\partial\\theta_i)^2$을 계산하는 것과 동일($\\theta_i$에 대한 비용 함수의 편미분을 제곱하여 누적함). 비용 함수가 i번째 차원을 따라 가파르다면 $s_i$는 반복이 진행되면서 점점 커짐.\n",
    "  * 2 : 경사 하강법과 비슷하지만, gradient 벡터를 $\\sqrt{\\mathbf{s}+\\epsilon}$으로 나눠 스케일을 조정. $\\epsilon$은 0으로 나누는 것을 막기 위한 아주 작은 값.\n",
    "* 학습률을 감소시키지만, 경사가 완만한 차원보다 가파른 차원에 더 빠르게 감소하고, 이를 적응적 학습률(adaptive learning rate)이라고 함.\n",
    "  * 차원별로 학습률은 다르게 감소.\n",
    "  * 전역 최적점으로 더 곧장 가도록 갱신되는 데 도움이 되고, 학습률 파라미터 $\\eta$를 덜 튜닝해도 된다는 장점이 있음.\n",
    "* 간단한 이차방정식 문제에 잘 작동하나, 신경망 훈련 시 학습률이 너무 감소되어 전역 최적점에 도달하기 전에 일찍 멈출 수 있음.\n",
    "  * keras에서 <code>Adagrad</code>를 사용할 수 있지만, 심층 신경망에서는 사용해선 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 너무 빨리 느려저 전역 최적점에 도달하지 못하는 AdaGrad의 단점을 개선한 것.\n",
    "* 훈련 시작부터 모든 gradient가 아닌 가장 최근 반복에서 비롯된 gradient만 누적.\n",
    "  * 알고리즘의 첫 번째 단계에서 지수 감소를 사용함.\n",
    "$$1.\\;\\mathbf{s}\\leftarrow\\beta\\mathbf{s}+(1-\\beta)\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\otimes\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$$\n",
    "$$2.\\;\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}-\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\oslash\\sqrt{\\mathbf{s}+\\epsilon}$$\n",
    "* 감쇄율 $\\beta$는 주로 0.9로 설정.\n",
    "  * 이도 조절해야할 하이퍼파라미터이지만, 기본값 0.9일때 대부분의 경우 잘 작동함.\n",
    "* <code>keras.optimizers.RMSprop(lr=0.001, rho=0.9)</code>와 같이 사용. rho값이 $\\beta$값\n",
    "* 간단한 문제를 제외하고는 항상 AdaGrad보다 성능이 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam(adaptive moment estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모멘텀 최적화와 RMSProp의 아이디어를 합친 것.\n",
    "* 모멘텀 최적화처럼 지난 gradient의 지수 감소 평균을 따르고, RMSProp처럼 지난 gradient의 제곱의 지수 감소된 평균을 따름.\n",
    "  * gradient의 평균과 분산에 대한 예측을 함. 평균을 첫 번째 모멘트, 분산을 두 번째 모멘트라고 함.\n",
    "$$1.\\;\\mathbf{m}\\leftarrow\\beta_1\\mathbf{m}-(1-\\beta_1)\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$$\n",
    "$$2.\\;\\mathbf{s}\\leftarrow\\beta_2\\mathbf{s}-(1-\\beta_2)\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\otimes\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$$\n",
    "$$3.\\;\\hat{\\mathbf{m}}\\leftarrow\\frac{\\mathbf{m}}{1-\\beta_1^t}$$\n",
    "$$4.\\;\\hat{\\mathbf{s}}\\leftarrow\\frac{\\mathbf{s}}{1-\\beta_2^t}$$\n",
    "$$5.\\;\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\eta\\hat{\\mathbf{m}}\\oslash\\sqrt{\\hat{\\mathbf{s}}+\\epsilon}$$\n",
    "  * t는 반복 횟수.\n",
    "  * 1, 2, 5단계가 모멘텀 최적화 및 RMSProp과 비슷. 대신 1에서 지수 감소 합 대신 지수 감소 평균을 계산.\n",
    "  * $\\mathbf{m},\\mathbf{s}$는 처음에 0으로 초기화되기 때문에 훈련 초기에 0쪽으로 치우치게 됨. 3, 4단계가 두 값을 증폭시키는데 도움을 줌. 즉, $\\mathbf{m},\\mathbf{s}$가 0부터 시작하므로 $\\beta_1\\mathbf{m}, \\beta_2\\mathbf{s}$가 반복 초기에 기여를 못하므로, 3,4단계에서 이를 증폭시켜줌. 대신 단계가 많이 진행될수록 3, 4단계의 분모는 1에 가까워져 $\\mathbf{m},\\mathbf{s}$값이 거의 증폭되지 않음.\n",
    "* 모멘텀 감쇠 파라미터 $\\beta_1$은 주로 0.9로 초기화하고 스케일 감쇠 파라미터 $\\beta_2$는 0.999로 주로 초기화함.\n",
    "* $\\epsilon$은 안정적인 계산을 위한 아주 작은 값(10^-7 등.)\n",
    "  * keras에서 <code>epsilon</code>의 기본값은 None으로, 기본값이 10^-7인 <code>keras.backend.epsilon()</code>을 사용.\n",
    "  * <code>keras.backend.set_epsilon()</code>을 사용해 바꿀 수 있음.\n",
    "* 학습률 파라미터 $\\eta$를 튜닝할 필요가 적음. 일반적으로는 기본값 0.001을 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AdaMax : Adam의 변종. Adam의 2단계에서 $\\mathbf{s}$에 gradient의 제곱을 누적하고(최근 gradient에 더 큰 가중치를 부여하고) 5단계에서 $\\epsilon$과 3,4단계를 무시하면 $\\mathbf{s}$의 제곱근으로 파라미터 업데이트의 스케일을 낮추게 됨. 즉, 시간이 지남에 따라 감쇠된 gradient의 $l_2$ norm(제곱의 합의 제곱근)으로 파라미터 업데이트의 스케일을 낮춤. AdaMax는 $l_2$ norm을 $l_\\infty$로 바꿈. \n",
    "  * Adam에서 2단계를 $\\mathbf{s}\\leftarrow\\text{max}\\left(\\beta_2\\mathbf{s},\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\right)$로 바꾸고, 4단계를 삭제한 것이 AdaMax가 됨.\n",
    "  * 5단계에서 $\\mathbf{s}$에 비례해 gradient 업데이트의 스케일을 낮춤.\n",
    "  * 실전에서 Adam보다 안정적이지만, 데이터셋에 따라 다르고, 일반적으로는 Adam의 성능이 더 좋기 때문에 어떤 작업에서 Adam이 잘 동작하지 않는다면 AdaMax optimizer를 사용할 수 있음.\n",
    "* Nadam : Adam+네스테로프 기법. Adam보다 조금 더 빠르게 수렴하고, 일반적으로 Adam보다 성능이 좋게 나오지만 때로는 RMSProp이 더 나을때도 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위의 모든 최적화 기법들은 1차 편미분(야코비안)에만 의존함.\n",
    "* 2차 편미분(헤시안) 기반 알고리즘들도 존재하지만, 심층 신경망에는 적용하기 어려움.\n",
    "  * 하나의 출력마다 n^2개의 2차 편미분을 계산해야 하기 때문(n은 파라미터 개수)\n",
    "  * 심층 신경망은 수만 개의 파라미터를 가지므로 메모리 용량을 초과할 수 있고, 가능하더라도 시간이 매우 오래 걸림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 최적화 알고리즘은 대부분의 파라미터가 0이 아닌 밀집(dense) 모델을 만듦. 이 대신에, 매우 빠르게 실행할 모델이 필요하거나 메모리를 적게 차지하는 모델이 필요하면 일부 가중치가 0인 희소(sparse)모델을 만들 수 있음.\n",
    "  * 보통 때처럼 훈련한 뒤, 작은 값의 가중치를 제거(0으로 만듦)하는 방식으로 만들 수 있음.\n",
    "  * 또는, $l_1$규제(이후 설명)를 강하게 적용(optimizer가 가능한 한 많은 가중치를 0으로 만들도록 강제).\n",
    "* 이도 잘 작동하지 않으면, 텐서플로 모델 최적화 툴킷(TF-MOT)을 사용해 훈련하는 동안 반복적으로 연결 가중치를 크기에 맞춰 제거하는 가지치기 API를 제공.\n",
    "  * https://www.tensorflow.org/model_optimization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|클래스|수렴 속도|수렴 품질|\n",
    "|-----|---------|--------|\n",
    "|SGD  |느림     |좋음     |\n",
    "|SGD(momentum=...)|보통|좋음|\n",
    "|SGD(momentum=...,nesterov=True)|보통|좋음|\n",
    "|Adagrad|빠름   |나쁨(너무 빨리 멈춤)|\n",
    "|RMSprop|빠름   |보통 또는 좋음|\n",
    "|Adam|빠름   |보통 또는 좋음|\n",
    "|Nadam|빠름   |보통 또는 좋음|\n",
    "|AdaMax|빠름   |보통 또는 좋음|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습률을 너무 크게 잡으면 훈련이 발산할 수 있고, 너무 작게 잡으면 최적점에 수렴하는 데 매우 오랜 시간이 걸림.\n",
    "* 컴퓨터 자원이 한정적이라면 차선의 솔루션을 만들기 위해 모델이 완전히 수렴하기 전에 훈련을 멈춰야 함.\n",
    "  * 이렇게 찾은 약간 높은 학습률은 처음에는 매우 빠르게 수렴하는 방향으로 진행하지만, 최적점 근처에서는 요동이 심해져 수렴하지 못하게 됨.\n",
    "* 매우 작은 값에서 시작해 매우 큰값까지 지수적으로 학습률을 중가시키며 모델 훈련을 수백번 반벅하여 좋은 학습률을 찾을 수 있음. 이후 학습 곡선을 보고 다시 상승하는 곡선보다 조금 더 작은 학습률을 선택한 뒤, 모델을 다시 초기화하고 이 학습률로 훈련.\n",
    "* 이 방법 대신, 큰 학습률로 시작해 학습 속도가 느려지면 학습률을 낮추는 방식을 사용할 수 있음. 이런 전략을 학습 스케줄(learning schedule)이라고 함.\n",
    "  * 최적의 고정 학습률보다 좋은 솔루션을 더 빨리 발견할 수 있음.\n",
    "  * 거듭제곱 기반 스케줄링 : 학습률을 반복 횟수 t에 대한 함수 $\\eta(t)=\\eta_0 / (1+t/s)^c$로 설정. $\\eta_0$는 초기 학습률, c는 거듭제곱 수(일반적으로 1), s는 step 횟수로, 이들 모두 하이퍼파라미터. 학습률은 각 step마다 감소되고 s번의 step뒤에 학습률은 $\\eta_0/2$로 줄어듦. s번마다 step을 반복할수록 학습률은 $\\eta_0/3$, $\\eta_0/4$...와 같이 줄어듦. 즉, 처음에는 학습률이 빠르게 감소하다가 나중에는 점점 더 느리게 감소함. $\\eta_0,s$,(아마 c도) 튜닝해야 제대로 작동함.\n",
    "  * 지수 기반 스케줄링 : 학습률을 $\\eta(t)=\\eta_00.1^{t/s}$로 설정. s step마다 10배씩 학습률이 줄어듦. 거듭제곱 기반 스케줄링은 학습률을 갈수록 천천히 감소시키지만, 지수 기반 스케줄링은 매 스텝마다 10배씩 계속 감소함.\n",
    "  * 구간별 고정 스케줄링 : 일정 횟수의 epoch동안 일정한 학습률을 사용하고, 그다음 또 다른 횟수의 epoch동안 작은 학습률을 사용하는 식으로 스케줄링. 잘 동작할 수 있지만, 적절한 학습률과 epoch횟수의 조합을 찾는 것이 힘듦.\n",
    "  * 성능 기반 스케줄링 : 조기 종료처럼 매 N step마다 검증 오차를 측정하고 오차가 줄어들지 않으면 $\\lambda$배만큼 학습률을 감소시킴.\n",
    "  * 1cycle 스케줄링 : 훈련 절반 동안 초기 학습룰 $\\eta_0$을 선형적으로 $\\eta_1$까지 증가시킨 뒤, 나머지 절반 동안 선형적으로 학습률을 다시 $\\eta_0$까지 줄임. 마지막 몇 epoch는 학습률을 소수점 몇 번재 자리까지 선형적으로 줄임. 최대 학습률 $\\eta_1$은 최적의 학습률을 찾을 때와 같은 방식을 이용해 선택하고, 초기 학습률 $\\eta_0$는 이보다 10배정도 낮은 값을 사용함.\n",
    "    * 모멘텀 사용 시 처음에 높은 모멘텀(ex. 0.95)으로 시작해 훈련의 처음 절반 동안 낮은 모멘텀으로 줄어듦(ex. 0.85). 이후 나머지 절반동안 최댓값(ex. 0.95)으로 되돌리고 마지막 몇 epoch는 최댓값을 유지한 채로 진행.\n",
    "    * 훈련 속도를 크게 높여주고 더 높은 성능을 낼 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거듭제곱 기반 스케줄링(구현이 가장 쉬움)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * <code>decay</code> : s의 역수. 기본값은 0이고, Adagrad, RMSProp, Adam, Adamax도 동일한 decay 매개변수를 지원함.\n",
    "> * keras에서 c는 1로 가정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지수 기반 스케줄링\n",
    "\n",
    "# 현재 epoch를 받아 학습률을 반환하는 함수 정의\n",
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch/20)\n",
    "\n",
    "# 또는 eta_0와 s를 하드코딩하지 않고 이 변수를 설정한 closure를 반환하는 함수를 만들 수도 있음.\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.01(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "\n",
    "# 이후 이 스케줄링 함수를 전달해 LearningRateScheduler 콜백을 만든 뒤, fit()메서드에 전달\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train, y_train, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * <code>LearningRateScheduler</code>는 epoch를 시작할 때 마다 optimizer의 learning_rate 속성을 업데이트함. 더 자주 업데이트 하고싶다면(ex. 매 step마다 업데이트) 사용자 정의 콜백을 만들 수 있음.\n",
    ">   * epoch마다 step이 많다면 스텝마다 학습률을 업데이트하는 것이 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케줄 함수는 두 번쨰 매개변수(현재 학습률)도 받을 수 있음.\n",
    "\n",
    "# 이전 학습률에 0.1^(1/20)을 곱해 동일한 지수 감쇠 효과를 내는 스케줄 함수\n",
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr*0.1**(1/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 저장 시 optimizer와 학습률이 같이 저장됨. \n",
    "* 새로운 스케줄 함수를 사용하더라도 훈련된 모델을 불러와 중지된 지점부터 훈련을 계속할 수 있음.\n",
    "  * 단, 스케줄 함수가 epoch매개변수를 사용한다면, 이는 저장되지 않고 fit()을 호출할 때 마다 0으로 초기화됨(중지된 지점에서 모델 훈련을 이어가면 매우 큰 학습률이 만들어질 수 있기 때문).\n",
    "  * 이를 해결하기 위해 epoch에서 시작하도록 fit()의 매개변수 <code>initial_epoch</code>를 수동으로 지정할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구간별 고정 스케줄링\n",
    "# 지수 기반 스케줄링과 동일하게 스케줄 함수로 LearningRateScheduler콜백을 만들어 fit()에 전달하는 방식으로 사용.\n",
    "\n",
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch<5:\n",
    "        return 0.01\n",
    "    elif epoch<15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "    \n",
    "# 또는 좀 더 일반적인 함수를 정의할 수 있음\n",
    "\"\"\"\n",
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 기반 스케줄링\n",
    "# ReduceLROnPlateau콜백을 사용.\n",
    "\n",
    "# 최상의 검증 손실이 5번의 연속적인 epoch동안 향상되지 않을 때 마다 학습률에 0.5를 곱함\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* keras에서는 <code>keras.optimizers.schedules</code>에 있는 스케줄 중 하나를 사용해 학습률을 정의하고, 이 학습률을 optimizer에 전달할 수 있음. 이렇게 하면 매 epoch가 아닌, 매 스텝마다 학습률을 업데이트함.\n",
    "  * 간결하고 이해하기 편함\n",
    "  * 모델 저장 시 학습률과 현재 상태를 포함한 스케줄도 함께 저장됨\n",
    "  * 단, 표준 keras api는 아니며 tf.keras에서만 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지수 기반 스케줄링\n",
    "s = 20 * len(X_train) // 32 # 20번 epoch에 담긴 전체 step 수. 배치 크기는 32\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1 cycle 방식은 매 반복마다 학습률을 조정하는 사용자 정의 콜백을 만들어 사용 가능.\n",
    "  * <code>self.model.optimizer.lr</code>(또는 <code>self.model.optimizer.learning_rate</code>)을 바꿔 optimizer의 학습률을 업데이트할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 지수 기반 스케줄링, 성능 기반 스케줄링, 1cycle 스케줄링이 수렴 속도를 크게 높일 수 있음.\n",
    "> 최근 연구에는 SGD, 모멘텀, 네스테로프 가속 경사 등에서 학습률 감소 대신 배치 크기를 늘리는 것으로 같은 효과를 낼 수 있다고도 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 과대적합을 피하는 데 사용함.\n",
    "* 심층 신경망은 파라미터가 매우 많으므로 자유도가 매우 높음. 즉, 대규모의 복잡한 데이터셋을 학습할 수 있음.\n",
    "* 그러나, 자유도가 높으면 훈련 세트에 과대적합될 수 있으므로 규제를 사용해야 함.\n",
    "* 조기 종료, 배치 정규화 등이 규제 방법으로 사용하고, 그 외에 $l_1$ 및 $l_2$규제, dropout, max-norm규제가 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $l_1, l_2$ 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 연결 가중치를 제한하기 위해 $l_2$규제를 사용하거나, 많은 가중치가 0인 희소 모델을 만들기 위해 $l_1$규제를 사용할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01))   # 규제 강도가 0.01인 l2규제 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <code>l2</code>함수는 훈련하는 동안 규제 손실을 계산하기 위해, 각 step에서 호출되는 규제 객체를 반환하고, 이 손실은 최종 손실에 합산됨.\n",
    "* $l_1$규제가 필요하면 <code>keras.regularizers.l1()</code>을 사용할 수 있고, l1과 l2둘 다 필요하다면 <code>regularizers.l1_l2(l1=..., l2=...)</code>와 같이 사용.\n",
    "* 일반적으로 모든 은닉층에 동일한 활성화 함수, 초기좌 전략, 규제를 적용하기 때문에 반복문을 사용하도록 refactoring하거나 <code>functools.partial()</code> 함수를 사용해 기본 매개변수 값을 사용하여 함수 호출을 감쌀 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가장 인기 있는 규제 기법 중 하나. 대부분의 경우에서 정확도의 상승을 기대할 수 있음.\n",
    "* 매 훈련 step마다 각 뉴런(입력 뉴런은 포함하고, 출력 뉴런은 제외)이 드랍아웃될 확룰 $p$를 가짐. 즉, $p$라는 확률에 따라 각 훈련 step에서 뉴런은 무시될수도 있고, 활성화될수도 있음.\n",
    "  * 하이퍼파라미터 $p$는 드롭아웃 비율(dropout rate)이라고 하고, 주로 10%~50%사이를 지정함.\n",
    "  * 순환 신경망에서는 20~30%, CNN에서는 40~50% 사용.\n",
    "* 훈련이 끝난 뒤에는 dropout을 적용하지 않음.\n",
    "* 드랍아웃으로 훈련된 뉴런은 이웃한 뉴런에 맞추어 적응되지 않고, 각각의 뉴런 자기 자신이 유용해지게 됨. 또한, 몇 개의 입력 뉴런에만 지나치게 의존하지 않고 모든 입력 뉴런에 주의를 기울이게 됨. 이는 입력의 작은 변화에 덜 민감해지게 되어 안정적인 네트워크를 만들어주고, 일반화 성능이 좋아짐.\n",
    "* 또한, 각 훈련 step에서 unique한 네트워크가 생성된다고 생각할 수 있음.\n",
    "  * 드랍아웃이 가능한 뉴런 수가 N개라면 $2^N$개의 unique한 네트워크가 생길 수 있고, 이 수는 매우 크므로 동일한 네트워크가 선택될 가능성이 매우 낮음.\n",
    "  * 이 신경망은 대부분의 가중치를 공유하고 있어 아주 독립적이진 않음에도 형태가 모두 다르므로 결과적으로 만들어진 신경망은 모든 신경망을 평균한 앙상블로 볼 수 있음.\n",
    "* 일반적으로 출력층을 제외하고 맨 위의 층부터 세 번째 층까지 있는 뉴런에만 드랍아웃을 적용함.\n",
    "* $p=50\\%$일 때, 테스트하는 동안에는 하나의 뉴런이 훈련 때보다 평균적으로 두 배 많은 입력 뉴런과 연결된다(테스트할 때는 드롭아웃을 적용하지 않으므로). 이를 보상하기 위해 훈련 뒤에는 각 뉴런의 연결 가중치에 0.5를 곱할 필요가 있음. 그렇지 않으면 각 뉴런이 훈련 시 보다 두배 많은 입력 신호를 받기 때문에 잘 동작하지 않을 수 있음.\n",
    "  * 일반적으로 표현하면 훈련이 끝난 뒤, 각 입력의 연결 가중치에 보존 확률(keep probability) $1-p$를 곱하거나, 훈련하는 동안 각 뉴런의 출력을 보존 확률로 나눌 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras에서의 드롭아웃 구현. keras.layers.Dropout층을 사용\n",
    "#   훈련하는 동안 일부 입력을 랜덤하게 버림(0으로 만듦). 그 뒤 남은 입력을 보존 확률로 나눔.\n",
    "#   훈련이 끝난 뒤에는 입력을 그대로 출력으로 전달함.\n",
    "#   Dropout층 이전의 층의 출력을 입력으로 받아 확률에 따라 그 일부를 dropout함.\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 드롭아웃은 훈련하는 동안에만 활성화되므로 훈련 손실과 검증 손실이 다르게 나올 수 있음. 따라서 훈련이 끝난 후 드롭아웃을 빼고 훈련 손실을 평가해야 함.\n",
    "* 모델이 과대적합되면 드롭아웃 비율을 늘릴 수 있고, 과소적합되면 드롭아웃 비율을 낮춰야 함.\n",
    "* 또한, 층이 클 때는 드롭아웃 비율을 늘리고 작은 층에는 드롭아웃 비율을 낮추는 것이 좋음.\n",
    "* 최근의 많은 신경망 구조는 마지막 은닉층 뒤에만 드롭아웃을 사용함(드롭아웃을 전체에 사용하는 것이 너무 강할 때 사용).\n",
    "* 드롭아웃은 수렴을 상당히 느리게 만들지만, 적절히 튜닝하면 훨씬 좋은 모델을 만듦.\n",
    "> SELU 활성화 함수를 기반으로 한 자기 정규화 네트워크를 규제하려면 alpha dropout(https://arxiv.org/pdf/1706.02515.pdf, New Dropout Technique)을 사용해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 몬테 카를로 드롭아웃\n",
    "* 훈련된 드롭아웃 모델을 재훈련하거나 수정하지 않고 성능을 향상시킬 수 있는 방법.\n",
    "* 드롭아웃을 활성화한 상태로 여러 개의 예측을 만들어 예측 결과를 평균함.\n",
    "* 드롭아웃 모델의 성능을 높여주고 더 정확한 불확실성 추정을 제공함.\n",
    "  * 훈련하는 동안은 일반적인 드롭아웃과 동일하므로 규제처럼 작동."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashoin_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashoin_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3931 - accuracy: 0.8535 - val_loss: 0.3310 - val_accuracy: 0.8786\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3892 - accuracy: 0.8567 - val_loss: 0.3295 - val_accuracy: 0.8822\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3914 - accuracy: 0.8554 - val_loss: 0.3349 - val_accuracy: 0.8784\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3873 - accuracy: 0.8559 - val_loss: 0.3263 - val_accuracy: 0.8800\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3861 - accuracy: 0.8571 - val_loss: 0.3248 - val_accuracy: 0.8814\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3884 - accuracy: 0.8566 - val_loss: 0.3243 - val_accuracy: 0.8798\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3833 - accuracy: 0.8580 - val_loss: 0.3246 - val_accuracy: 0.8812\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3816 - accuracy: 0.8581 - val_loss: 0.3247 - val_accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3815 - accuracy: 0.8605 - val_loss: 0.3200 - val_accuracy: 0.8826\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3784 - accuracy: 0.8594 - val_loss: 0.3225 - val_accuracy: 0.8822\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3786 - accuracy: 0.8598 - val_loss: 0.3204 - val_accuracy: 0.8834\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3741 - accuracy: 0.8600 - val_loss: 0.3246 - val_accuracy: 0.8812\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3753 - accuracy: 0.8603 - val_loss: 0.3192 - val_accuracy: 0.8838\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3744 - accuracy: 0.8603 - val_loss: 0.3236 - val_accuracy: 0.8822\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3741 - accuracy: 0.8603 - val_loss: 0.3169 - val_accuracy: 0.8838\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3740 - accuracy: 0.8616 - val_loss: 0.3166 - val_accuracy: 0.8820\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3711 - accuracy: 0.8615 - val_loss: 0.3231 - val_accuracy: 0.8814\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3712 - accuracy: 0.8637 - val_loss: 0.3163 - val_accuracy: 0.8814\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3708 - accuracy: 0.8627 - val_loss: 0.3144 - val_accuracy: 0.8848\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3687 - accuracy: 0.8645 - val_loss: 0.3176 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f5ea1d430>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test,  training=True) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * <code>model(X)</code> : <code>model.predict(X)</code>와 비슷. 단, tensor를 반환함.\n",
    "> * <code>training=True</code> 로 지정했기 때문에 Dropout층이 활성화되어 예측이 달라짐.\n",
    "> * test set으로부터 100개의 예측을 만들어 쌓음. 모델을 호출할 때 마다 샘플이 행이고, 클래스마다 하나의 열을 가진 행렬이 반환됨. 즉, test set에 10000개의 샘플과 10개의 클래스가 있으므로 행렬의 크기는 [10000, 10]이 됨. 이를 100개 쌓았기 때문에 y_probas는 [100, 10000, 10]크기가 됨.\n",
    "> * <code>.mean(axis=0)</code>은 첫 번재 차원을 기준으로 평균을 냄. 결과로 나온 y_proba의 크기는 [10000, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위처럼 드롧아웃으로 만든 예측들을 평균하면 드롭아웃 없이 예측한 하나의 결과보다 더 안정적으로 나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout없이 예측한 결과\n",
    "pred = np.round(model.predict(X_test[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.13, 0.  , 0.84]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24f56dc8fa0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(f\"label : {y_test[:1][0]}, predict : {np.argmax(pred)}\")\n",
    "plt.imshow(X_test[:1][0], cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.23, 0.  , 0.51]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.13, 0.02, 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.12, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 0.  , 0.16, 0.  , 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.05, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.18, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.11, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.05, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.09, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.02, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.42, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.06, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.22, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.04, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.2 , 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.02, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.29, 0.  , 0.63]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.06, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.13, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.07, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.18, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.13, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.19, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.07, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.21, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.48, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.08, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.21, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.16, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 0.  , 0.05, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.18, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.12, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.06, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.12, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.39, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.08, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.13, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.14, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.12, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.1 , 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.64, 0.  , 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.21, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.42, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.27, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.19, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.25, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.18, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.03, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.21, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.15, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.27, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.46, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.18, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.46, 0.  , 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.09, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.11, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.12, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.45, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.03, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.2 , 0.01, 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.17, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.01, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.14, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.05, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.16, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.61, 0.  , 0.36]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.33, 0.03, 0.39]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.26, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.27, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.18, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.77, 0.  , 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.19, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.3 , 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.06, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.25, 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.2 , 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.01, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.07, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.07, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.11, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.17, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.2 , 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.37, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.28, 0.  , 0.39]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.53, 0.  , 0.41]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropout을 활성화한 상태에서의 여러 예측\n",
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * dropout을 끈 상태에서 모델은 첫 번째 test set 데이터에 대해 84%의 확률로 ankle boot라고 예측\n",
    "> * dropout을 활성화한 상태에서는 끈 상태보다 ankle boot라는 예측을 좀 더 약하게 함.\n",
    ">   * 신발이라는 공통점을 가진 라벨인 샌들(5)과 스니커즈(7)로 예측하기도 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.17, 0.  , 0.71]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_probas를 평균낸 결과.\n",
    "# dropout없이 예측한 결과보다 확신을 덜 함.(71%)\n",
    "\n",
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.15, 0.  , 0.18]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률 추정의 표준 분포 확인\n",
    "\n",
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 드롭아웃이 적용된 예측으로 정확도 출력\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "np.sum(y_pred == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 의료 및 금융 서비스 등 위험에 민감한 시스템을 만들 때 불확실한 예측을 주의깊게 다뤄야 함.\n",
    "  * 드롭아웃을 적용하지 않은 예측과 같은 높은 확신을 가진 예측으로 다루어서는 안됨.\n",
    "* 몬테 카를로 샘플의 숫자(위에서는 100개)는 튜닝 가능.\n",
    "  * 값이 높을수록 예측과 불확실성 추정이 정확해지지만, 수가 두 배로 늘어나면 예측 시간도 두 배로 늘어남.\n",
    "  * 또한, 일정 수 이상 넘어가면 성능 향상이 크지 않음.\n",
    "* <code>BatchNormalization</code>층과 같이 모델이 훈련하는 동안 다르게 작동하는 층이 있다면 훈련 모드를 강제로 설정하면 안 됨.\n",
    "  * <code>Dropout</code>층을 아래와 같은 <code>MCDropout</code>로 바꿔 해결가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * <code>Dropout</code>을 상속해 <code>call()</code>을 오버라이드하여 training 매개변수를 강제로 True로 설정\n",
    "> * 모든 keras API에서 사용가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max-Norm 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 뉴런에 대한 입력 연결 가중치 $\\mathbf{w}$가 $\\parallel\\mathbf{w}\\parallel_2\\leq r$이 되도록 제한.\n",
    "  * r은 max-norm 하이퍼파라미터이고, $\\parallel\\;\\parallel_2$는 $l_2$ norm\n",
    "* 전체 손실 함수에 규제 손실 항을 추가하지 않고 매 훈련 스텝이 끝날 때 $\\parallel\\mathbf{w}\\parallel_2$를 계산하고 필요하면 $\\mathbf{w}$의 스케일을 조정함($\\displaystyle\\mathbf{w}\\leftarrow\\mathbf{w}\\frac{r}{\\parallel\\!w\\!\\parallel_2}$)\n",
    "* r을 줄이면 규제의 양이 커져 과대적합을 감소시킬 수 있음.\n",
    "* 불안정한 gradient문제를 완화하는 데 도움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x24f56de8fa0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras에서의 max-norm 규제 사용\n",
    "# 적절한 최댓값으로 지정한 max_norm()이 반환한 객체로 은닉층의 kernel_constraint 매개변수 지정\n",
    "\n",
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 매 훈련 반복이 끝난 후 fit()이 층이 가중치와 함깨 max_norm()이 반환한 객체를 호출하고 스케일이 조정된 가중치를 받음.\n",
    "* max_norm()에는 axis 매개변수(기본값 0) 존재. Dense층은 보통 [샘플 개수, 뉴런 개수] 크기의 가중치를 가지는데 axis=0를 사용하면 각 뉴런의 가중치 벡터에 독립적으로 적용\n",
    "  * CNN에서 axis 매개변수를 적절히 조정해야함(<code>axis=[0,1,2]</code>와 같이)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리 및 가이드라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반적으로 잘 맞는 설정(절대적인 것은 아님.)\n",
    "\n",
    "|하이퍼파라미터|기본값|\n",
    "|------------|------|\n",
    "|커널 초기화|He 초기화|\n",
    "|활성화 함수 |ELU     |\n",
    "|정규화      |얕은 신경망-없음, 깊은 신경망-배치 정규화|\n",
    "|규제        |조기 종료(필요 시 l2 추가)|\n",
    "|optimizer  |모멘텀, RMSProp, Nadam|\n",
    "|학습률 스케줄|1cycle|\n",
    "\n",
    "* 네트워크가 완전 연결 층을 쌓은 단순한 모델이면 자기 정규화 사용 가능. 이런 경우에서의 일반적으로 잘 맞는 설정\n",
    "\n",
    "|하이퍼파라미터|기본값|\n",
    "|------------|------|\n",
    "|커널 초기화|LeCun 초기화|\n",
    "|활성화 함수 |SELU     |\n",
    "|정규화      |없음(자기 정규화됨)|\n",
    "|규제        |알파 드롭아웃(필요 시)|\n",
    "|optimizer  |모멘텀, RMSProp, Nadam|\n",
    "|학습률 스케줄|1cycle|\n",
    "\n",
    "* 입력 특성은 정규화가 필요.\n",
    "* 비슷한 문제를 해결한 모델을 찾을 수 있다면 사전훈련된 신경망의 일부를 재사용하는 것이 좋음.\n",
    "* 레이블이 없는 데이터가 많다면 비지도 사전훈련 사용\n",
    "* 비슷한 작업을 위한 레이블된 데이터가 많다면 보조 작업에서 사전훈련 수행\n",
    "* 희소 모델이 필요하다면 $l_1$규제를 사용할 수 있음.\n",
    "  * 매우 희소한 모델이 필요하다면 TF-MOT 사용 가능. 단, 자기 정규화를 깨뜨리므로 위의 일반적으로 잘 맞는 설정을 사용해야 함.\n",
    "* 빠른 응답을 하는 모델(예측이 매우 빠른 모델)이 필요하다면 층 개수를 줄이고 배치 정규화 층을 이전 층에 합침. 또한, LeakyReLU와 ReLU같이 빠른 활성화 함수를 써도 되고 희소 모델을 만드는 것도 도움이 됨. 부동소수점 정밀도를 낮출 수도 있음.\n",
    "* 위험에 민감하고 예측 속도가 중요하지 않다면 MC 드롭아웃 사용"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4211a37325b67dc4346d743008529599135417ca8cd1eae7178b10ad33111a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
